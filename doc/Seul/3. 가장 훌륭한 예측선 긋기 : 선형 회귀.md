딥러닝의 가장 말단에서 이루어지는 가장 기본적이 두 가지 계선 원리
- 선형회귀 : 가장 훌륭한 예측선 긋기
- 로지스틱 

머신러닝은 제대로 된 선을 긋는 작업부터 시작

# 선형 회귀의 정의

'정보' 요소를 x라고 하고, 이 x값에 의해 변하는 y가 있음  
x 값이 변함에 따라 y 값도 변한다는 이 정의 안에서  
**독입 변수**  : 독립적으로 변할 수 있는 값 x  
**종속 변수** : 독립 변수에 따라 종속적으로 변하는 y

선형 회귀 : 독립 변수 x를 사용해 종속 변수 y의 움직임을 예측하고 설명하는 작업  
**단순 선형 회귀**(simple linear refression) : 하나의 x 값만으로도 y 값을 설명할 수 있을 때  
**다중 선형 회귀**(multiple linear regression) : x 값이 여러개 필요할 때


